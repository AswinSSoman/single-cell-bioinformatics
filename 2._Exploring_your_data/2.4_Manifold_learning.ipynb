{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold learning\n",
    "\n",
    "## What is a manifold?\n",
    "\n",
    "Manifolds are multi-dimensional surfaces that could look flat if you're up really really close but from far away are curved. The classic example of a manifold is a torus, or \"donut\", of which all of the below are from.\n",
    "\n",
    "![](figures/torii.jpg)\n",
    "\n",
    "The idea behind  manifold embedding algorithms is to maintain the high dimensional structure of the manifold, but plot the data in two dimensions.\n",
    "\n",
    "The math behind these algorithms is actually quite simple. We want to convert each point in high dimensions to a point in two dimensions:\n",
    "\n",
    "* High dimensional data of samples $\\vec{x}_i$ in $N$-dimensional gene space: $\\vec{x}_1, \\vec{x}_2, \\ldots \\vec{x}_N$\n",
    "* Low dimensional data $\\vec{y}_i = \\vec{y}_{i, 1}, \\vec{y}_{i, 2}$ (2-dimensional cartesian plane) - $\\vec{y}_1, \\vec{y}_2, \\ldots \\vec{y}_N$\n",
    "\n",
    "Visually, you can think of converting each high $N$-dimensional sample $i$'s gene expression vector $x_i$ to a length 2 vector:\n",
    "\n",
    "<center>\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "           x_{i, 1} \\\\\n",
    "           x_{i, 2} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{i, N}\n",
    "\\end{bmatrix} \\rightarrow \\begin{bmatrix}\n",
    "           y_{i, 1} \\\\\n",
    "           y_{i, 2}\n",
    "\\end{bmatrix}\n",
    "         $\n",
    "</center>\n",
    "\n",
    "We'll compare MDS and t-SNE side by side once we get a brief introduction to both.\n",
    "\n",
    "\n",
    "## Multidimensional scaling (MDS)\n",
    "\n",
    "Multidimensional scaling is an algorithm which faithfully maintains all pairwise distances between the points in the dataset.\n",
    "\n",
    "## t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "t-SNE is an extension of MDS. In addition to maintaining pairwise distances, t-SNE adds the constraint that things that were far apart in the high-dimensional data should also be far apart in 2d, and that things that are close together in high dimensions should stay close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.decomposition import FastICA, PCA \n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook')\n",
    "import ipywidgets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "### Manifold learning dimensionality reduction: MDS and t-SNE\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "# Author: Jake Vanderplas -- <vanderplas@astro.washington.edu>\n",
    "\n",
    "\n",
    "import scipy\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "# Next line to silence pyflakes. This import is needed.\n",
    "Axes3D\n",
    "\n",
    "def compare_mds_tsne(stddev=0, metric='euclidean', tsne_init='pca'):\n",
    "    n_points = 1000\n",
    "    random_state = 0\n",
    "    X, sample_order = datasets.samples_generator.make_s_curve(n_points, random_state=0)\n",
    "\n",
    "    if stddev > 0:\n",
    "        X = X + np.random.normal(size=np.product(X.shape), scale=0.1).reshape(X.shape)\n",
    "        \n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(\"Manifold Learning with %i points\" % (n_points))\n",
    "    \n",
    "    # Plot original data\n",
    "    ax = fig.add_subplot(131, projection='3d')\n",
    "    ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=sample_order, cmap=cmap)\n",
    "    ax.view_init(4, -72)\n",
    "\n",
    "    # Add noise if necessary\n",
    "    n_components = 2\n",
    "    smusher_kws = dict(n_components=n_components, random_state=random_state)\n",
    "    tsne_kws = dict(init=tsne_init)\n",
    "    \n",
    "    if metric != 'euclidean':\n",
    "        X = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(X, metric=metric))\n",
    "        smusher_kws['metric'] = 'precomputed'\n",
    "        \n",
    "        print('FYI not initializing t-SNE with PCA since distances are precomputed')\n",
    "        tsne_kws.pop('init')\n",
    "    tsne_kws.update(smusher_kws)\n",
    "    \n",
    "\n",
    "    # Perform MDS and plot it\n",
    "    t0 = time()\n",
    "    mds = manifold.MDS(max_iter=100, n_init=1, **smusher_kws)\n",
    "    Y = mds.fit_transform(X)\n",
    "    t1 = time()\n",
    "    print(\"MDS: %.2g sec\" % (t1 - t0))\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c=sample_order, cmap=cmap)\n",
    "    plt.title(\"MDS (%.2g sec)\" % (t1 - t0))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Perform t-SNE and plot it\n",
    "    t0 = time()\n",
    "    tsne = manifold.TSNE(**tsne_kws)\n",
    "    Y = tsne.fit_transform(X)\n",
    "    t1 = time()\n",
    "    print(\"t-SNE: %.2g sec\" % (t1 - t0))\n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c=sample_order, cmap=cmap)\n",
    "    plt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    plt.axis('tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "ipywidgets.interact(compare_mds_tsne, \n",
    "                    metric=ipywidgets.Dropdown(options=['euclidean', 'cityblock'], \n",
    "                                               value='euclidean', description=\"Distance Metric\"), \n",
    "                    tsne_init=['random', 'pca'], \n",
    "                    n_points=ipywidgets.IntSlider(value=1000, min=50, max=2000, step=50),\n",
    "#                     random_state=ipywidgets.IntSlider(value=0, min=0, max=10),\n",
    "                    stddev=ipywidgets.FloatSlider(value=0, min=0, max=1, \n",
    "                                                  description='Add Noise? (value = std dev of normal distribution)', step=0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 2.4.1\n",
    "\n",
    "While you're playing with the sliders above, work on this [quiz](https://docs.google.com/forms/d/1pTfYEZdUsV2PQ5aD4Lo8O__mlp9SmfNFwYCmOPVUMU8/viewform)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
