{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring your data with unsupervised machine learning\n",
    "\n",
    "## Dimensionality reduction\n",
    "\n",
    "Dimensionality reduction algorithms like PCA, ICA, MDS, t-SNE (we'll get into the acronyms in a second) are all trying to accomplish the same thing: *smush your high dimensional data into a palatable number of dimensions* (often <10).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix decomposition methods: PCA and ICA\n",
    "\n",
    "The two first methods we will talk about are true matrix decomposition methods. They are trying to decompose a matrix $X$ into constitutent parts, $Y$ and $W$.\n",
    "\n",
    "$Y = WX$\n",
    "\n",
    "#### Principal Component Analysis (PCA)\n",
    "\n",
    "Principal component analysis f\n",
    "\n",
    "#### Independent Component Analysis (ICA)\n",
    "\n",
    "ICA was originally created for the \"cocktail party problem\" for audio processing. It's an incredible feat that our brains are able to filter out all these different sources of audio, automatically!\n",
    "\n",
    "![](figures/Cocktail-party-_2502341b.jpg)\n",
    "(I really like how smug that guy looks - it's really over the top)\n",
    "[Source](http://www.telegraph.co.uk/news/science/science-news/9913518/Cocktail-party-problem-explained-how-the-brain-filters-out-unwanted-voices.html)\n",
    "\n",
    "##### Cocktail party problem\n",
    "\n",
    "Given multiple sources of sound (people talking, the band playing, glasses clinking), how do you distinguish independent sources of sound? Imagine at a cocktail party you have multiple microphones stationed throughout, and you get to hear all of these different sounds. \n",
    "\n",
    "![](figures/independent-component-analysis-ica-the-cocktail-party-problem-n.jpg)\n",
    "\n",
    "[Source](http://www.slideserve.com/vladimir-kirkland/ica-and-isa-using-schweizer-wolff-measure-of-dependence)\n",
    "\n",
    "\n",
    "##### What if you applied PCA to the cocktail party problem?\n",
    "\n",
    "What would you get if you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering\n",
    "\n",
    "### Distance metrics: Euclidean vs Manhattan\n",
    "One important point of how you cluster data is which \n",
    "\n",
    "- Euclidean distance is what you learned in algebra class: $\\sqrt{x^2 + y^2}$, but all the way to $N$ dimensions: $\\sqrt{\\sum_i^N x_i^2}$\n",
    "- Manhattan distance (also called \"taxicab geometry\")\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Manhattan_distance.svg/2000px-Manhattan_distance.svg.png)\n",
    "\n",
    "### Linkage methods: Ward, average, single, complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olga/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.clustermap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
