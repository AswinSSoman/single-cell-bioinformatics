{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FastICA, PCA \n",
    "\n",
    "sns.set(style='white', context='notebook')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering\n",
    "\n",
    "### Distance metrics: Euclidean vs Manhattan\n",
    "One important point of how you cluster data is which distance metric you use.\n",
    "\n",
    "- Euclidean distance is what you learned in algebra class: $d(x, y) = \\sqrt{x^2 + y^2}$, but all the way to $N$ dimensional vectors ($\\vec{x}, \\vec{y}$ represent $N$-dimensional vectors): $d(\\vec{x}, \\vec{y}) = \\sqrt{\\sum_i^N \\left(x_i -y_i\\right)^2}$\n",
    "- Manhattan distance (also called \"taxicab geometry\") is similar but no squares or square roots: $d(\\vec{x}, \\vec{y}) = \\sum_i^N |x_i - y_i|$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Manhattan_distance.svg/283px-Manhattan_distance.svg.png)\n",
    "\n",
    "### Correlation metrics\n",
    "\n",
    "#### Spearman correlation\n",
    "[Spearman correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)`\n",
    "answers the simple question, every time $x$ increases, does $y$ increase also? If yes, then spearman correlation = 1.\n",
    "\n",
    "Mathematically speaking, pearson tells you whether $x$ and $y$ increase monotonically together\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Spearman_fig1.svg/360px-Spearman_fig1.svg.png)\n",
    "\n",
    "\n",
    "#### Pearson correlation\n",
    "[Pearson Correlation](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient) answers the question, every time my $x$ decreases by some amount $a$, does $y$ decrease by an amount proportional to that, say $10a$ or $0.5a$, and is this amount constant?\n",
    "\n",
    "$\\rho_{x,y} = \\frac{\\mathrm{cov}(\\vec{x}, \\vec{y})}{\\sigma_x, \\sigma_y}$\n",
    "\n",
    "Mathematically speaking, pearson tells you whether $x$ and $y$ are *linear* to each other.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png)\n",
    "\n",
    "#### Spearman vs Pearson\n",
    "\n",
    "Spearman's correlation is related to Pearson because Spearman \n",
    "\n",
    "Spearman correlation = Pearson correlation on the ranks of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anscombe's quartet \n",
    "\n",
    "Anscombe's quartet is a group of four datasets that have nearly identical statistical properties that we'll use for exploring distance and correlation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anscombe = sns.load_dataset('anscombe')\n",
    "\n",
    "x = np.arange(4, 21)\n",
    "y = 3 + 0.5*x\n",
    "\n",
    "g = sns.FacetGrid(anscombe, col='dataset', col_wrap=2)\n",
    "g.map(plt.scatter, 'x', 'y')\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot(x, y, '-', color='k', zorder=-1, linewidth=0.5)\n",
    "    ax.set(xlim=(4, 20), ylim=(4, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = anscombe.groupby('dataset')\n",
    "\n",
    "statistical = 'mean', 'var', 'std'\n",
    "\n",
    "def explore_anscombe(summary):\n",
    "    col = None\n",
    "    \n",
    "    if summary in statistical:\n",
    "        summarized = getattr(grouped, summary)()\n",
    "        tidy = summarized.unstack().reset_index()\n",
    "        tidy = tidy.rename(columns={'level_0': 'variable', 0: summary})\n",
    "        col = 'variable'\n",
    "    else:\n",
    "        if summary.endswith('correlation'):\n",
    "            method = summary.split()[0].lower()\n",
    "            summarized = grouped.apply(lambda df: df['x'].corr(df['y'], method=method))\n",
    "        elif summary.endswith('distance'):\n",
    "            metric = getattr(distance, summary.split()[0].lower())\n",
    "            summarized = grouped.apply(lambda df: metric(df['x'], df['y'])) \n",
    "        tidy = summarized.reset_index()\n",
    "        tidy = tidy.rename(columns={'index': 'variable', 0: summary})\n",
    "    print(summarized.T)\n",
    "\n",
    "    g = sns.factorplot(data=tidy, col=col, x='dataset', \n",
    "                       y=summary, kind='bar', size=3, zorder=-1)\n",
    "    for ax in g.axes.flat:\n",
    "        # add a white grid on top\n",
    "        ax.grid(axis='y', color='white', zorder=2)\n",
    "    \n",
    "ipywidgets.interact(explore_anscombe,\n",
    "                    summary=['mean', 'var', 'std', \n",
    "                             'Pearson correlation', \n",
    "                             'Spearman correlation',\n",
    "                             'Euclidean distance', \n",
    "                             'Cityblock distance']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.1.1\n",
    "\n",
    "Open up this [quiz](https://docs.google.com/forms/d/1DmGgjhvI_IWagsyANoMmv9dgRRZcw8JPJasY-AqKWeU/viewform) to work on while you play with the widgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linkage methods: Ward, average, single, complete\n",
    "\n",
    "![Linkage methods](figures/linkage_methods.jpg)\n",
    "\n",
    "* Single: Compares shortest distance between clusters\n",
    "* Complete: Compares largest distance between clusters\n",
    "* Average: Compares average distance between clusters\n",
    "* Ward: Within cluster, compares average distance to centroid\n",
    "* Centroid: Compares centroid points of clusters\n",
    "\n",
    "source: http://www.slideshare.net/neerajkaushik/cluster-analysis\n",
    "\n",
    "\n",
    "We'll use a couple different datasets for studying linkage methods\n",
    "\n",
    "#### \"Mouse data\"\n",
    "\n",
    "WE'll use the same \"mouse data\" we used yesterday for looking at bach effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2016)\n",
    "\n",
    "n_samples = 10\n",
    "n_genes = 20\n",
    "\n",
    "half_genes = int(n_genes/2)\n",
    "half_samples = int(n_samples/2)\n",
    "size = n_samples * n_genes\n",
    "\n",
    "genes = ['Gene_{}'.format(str(i+1).zfill(2)) for i in range(n_genes)]\n",
    "samples = ['Sample_{}'.format(str(i+1).zfill(2)) for i in range(n_samples)]\n",
    "\n",
    "mouse_data = pd.DataFrame(np.random.randn(size).reshape(n_samples, n_genes), index=samples, columns=genes)\n",
    "\n",
    "# Add biological variance\n",
    "mouse_data.iloc[:half_samples, :half_genes] += 1\n",
    "mouse_data.iloc[:half_samples, half_genes:] += -1\n",
    "mouse_data.iloc[half_samples:, half_genes:] += 1\n",
    "mouse_data.iloc[half_samples:, :half_genes] += -1\n",
    "\n",
    "# Z_score within genes\n",
    "mouse_data = (mouse_data - mouse_data.mean())/mouse_data.std()\n",
    "\n",
    "# Biological samples\n",
    "mouse_groups = pd.Series(dict(zip(data.index, (['Mouse_01'] * int(n_samples/2)) + (['Mouse_02'] * int(n_samples/2)))), \n",
    "                         name=\"Mouse\")\n",
    "mouse_to_color = dict(zip(['Mouse_01', 'Mouse_02'], ['lightgrey', 'black']))\n",
    "mouse_colors = [mouse_to_color[mouse_groups[x]] for x in samples]\n",
    "\n",
    "# Gene colors\n",
    "gene_colors = sns.color_palette('Greens', n_colors=half_genes) + \\\n",
    "    sns.color_palette(\"Purples\", n_colors=half_genes)\n",
    "\n",
    "mouse_row_colors = mouse_colors\n",
    "mouse_col_colors = gene_colors \n",
    "\n",
    "g = sns.clustermap(mouse_data, row_colors=mouse_row_colors, col_cluster=False, row_cluster=False, \n",
    "                   linewidth=0.5, col_colors=mouse_col_colors,\n",
    "                   cbar_kws=dict(label='Normalized Expression'))\n",
    "plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudotime data\n",
    "\n",
    "We'll use an artificial \"psuedotime\" ordered dataset, where some genes turn on or off along the data, nonlinearly, plus there's an intermediate population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2016)\n",
    "\n",
    "n_samples = 10\n",
    "n_genes = 20\n",
    "\n",
    "half_genes = int(n_genes/2)\n",
    "half_samples = int(n_samples/2)\n",
    "size = n_samples * n_genes\n",
    "\n",
    "genes = ['Gene_{}'.format(str(i+1).zfill(2)) for i in range(n_genes)]\n",
    "samples = ['Sample_{}'.format(str(i+1).zfill(2)) for i in range(n_samples)]\n",
    "\n",
    "pseudotime_data = pd.DataFrame(np.random.randn(size).reshape(n_samples, n_genes), index=samples, columns=genes)\n",
    "\n",
    "# Add \"psueodotime\"\n",
    "pseudotime_data.iloc[:, :half_genes] = pseudotime_data.iloc[:, :half_genes].add(np.square(np.arange(n_samples)/2), axis=0)\n",
    "pseudotime_data.iloc[:, half_genes:] = pseudotime_data.iloc[:, half_genes:].add(np.square(np.arange(n_samples)[::-1]/2), axis=0)\n",
    "\n",
    "\n",
    "# Normalize genes using z-scores\n",
    "pseudotime_data = (pseudotime_data - pseudotime_data.mean())/data.std()\n",
    "\n",
    "pseudotime_row_colors = sns.color_palette('BrBG', n_colors=n_samples)\n",
    "pseudotime_col_colors = sns.color_palette(\"PRGn\", n_colors=n_genes)\n",
    "tidy = pseudotime_data.unstack().reset_index()\n",
    "tidy = tidy.rename(columns={'level_0': 'Gene', 'level_1': \"Sample\", 0:'Normalized Expression'})\n",
    "tidy.head()\n",
    "\n",
    "g = sns.factorplot(data=tidy, hue='Gene', palette=pseudotime_col_colors, x='Sample', \n",
    "                   y='Normalized Expression', aspect=2)\n",
    "# g.map(plt.plot, x='Sample', y='Normalized Expression')\n",
    "\n",
    "\n",
    "g = sns.clustermap(pseudotime_data, row_colors=pseudotime_row_colors, col_cluster=False, row_cluster=False, \n",
    "                   linewidth=0.5, col_colors=pseudotime_col_colors,\n",
    "                   cbar_kws=dict(label='Normalized Expression'))\n",
    "plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def explore_clustering(dataset, metric, method, row_cluster, col_cluster, correlate):\n",
    "    if dataset == \"Mouse\":\n",
    "        data = mouse_data\n",
    "        col_colors = mouse_col_colors\n",
    "        row_colors = mouse_row_colors\n",
    "    elif dataset == 'Pseudotime':\n",
    "        data = pseudotime_data\n",
    "        col_colors = pseudotime_col_colors\n",
    "        row_colors = pseudotime_row_colors        \n",
    "    if correlate != \"No\":\n",
    "        data = data.T.corr(method=correlate.lower())\n",
    "        col_colors = row_colors\n",
    "    \n",
    "    g = sns.clustermap(data, figsize=(6, 6), #annot=True, fmt='d', \n",
    "                       row_colors=row_colors, col_colors=col_colors, \n",
    "                       metric=metric, method=method,\n",
    "                      col_cluster=col_cluster, row_cluster=row_cluster)\n",
    "    plt.setp(g.ax_heatmap.get_yticklabels(), rotation='horizontal');\n",
    "    if col_cluster or row_cluster:\n",
    "        title_suffix = ' with {} clustering on {} metric'.format(method, metric)\n",
    "    else:\n",
    "        title_suffix = ''\n",
    "    g.fig.suptitle('{} data'.format(dataset) + title_suffix)\n",
    "    \n",
    "ipywidgets.interact(explore_clustering,\n",
    "                    dataset=ipywidgets.Dropdown(options=['Mouse', 'Pseudotime'], value='Mouse', \n",
    "                                                description='Dataset'),\n",
    "                    metric=ipywidgets.Dropdown(options=['euclidean', 'cityblock', ], value='euclidean', \n",
    "                                               description='Distance metric'),\n",
    "                    method=ipywidgets.Dropdown(options=['complete', 'single', 'average', 'ward', 'centroid'], value='average', \n",
    "                                               description='Linkage method'),\n",
    "                    row_cluster=ipywidgets.Checkbox(value=True, description='Cluster rows?'),\n",
    "                    col_cluster=ipywidgets.Checkbox(value=True, description='Cluster columns?'),\n",
    "                    correlate=ipywidgets.Dropdown(\n",
    "        options=['No', 'Pearson', 'Spearman'], value='No', description='Cluster on correlations?'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up this [quiz](https://docs.google.com/forms/d/1bByfKEkLdxzKeNd_NyIrjSZGCCq2GK0cTCW4Fne1GPQ/viewform) to work on while you play with the widgets.\n",
    "\n",
    "For these questions, don't cluster on sample correlations. The option is there for you if you want to see the difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
